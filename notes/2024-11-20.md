# Notes from Weds 20 November 2024
`Last commit: 86cdaa8`
## Recent changes
#### Lambda layers
The original repo had Lambda layers, which have [(de)serialization limitations](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda).
> Lambda layers are saved by serializing the Python bytecode, which is fundamentally non-portable and potentially unsafe. They should only be loaded in the same environment where they were saved. Subclassed layers can be saved in a more portable way by overriding their get_config() method. Models that rely on subclassed Layers are also often easier to visualize and reason about.

I created a new python module called `lambdas.py` with `tf.keras.layers.Layer` subclasses and import these. Then I call these layers as `lambdas.SubClassName`, in the same way normal layers are called using `layers.SubClassName`. This solves saving and loading.

However, trying to load the pretrained weights I get a mismatch in the number of layers. My code has 33 layers in the generator and 19 in the discriminator, but the pretrained weights are for 31 and 13. I can't see where this could be coming from.

#### Other changes
I also split the main script from the StyleGAN2 definition to clean things up. DiffAugment is working.

#### Linux branch
This branch has been reverted to the original TF2 repository, (without Apple Silicon mods). I haven't got it working on the cluster yet. There are also some bugs that I need to resolve. Same bugs as on the silicon repo. I might be able to identify these on the Mac before moving to the cluster, if I only use Tensorflow with CPU, which is fine since I'm not training yet.

## Next Steps
1. Debug linux branch
2. Try quick training on the cluster
3. Re-read DiffAugment and StylGAN2 papers
4. Try few-shot training on cluster
5. Add DiffAugment and repeat